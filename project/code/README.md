# Code

The exploration and preprocessing for each dataset was done in Jupyter Notebooks through Google Colab.

You can find the notebooks in this folder.

To use them simply click them, and then click the "Open in Colab" button, at the top left corner.

Each notebook contains three sections:
1. Description
   
This bit will explain the purpose of the dataset, the list of features it contains, and where the dataset comes from (the Kaggle links are provided inside the notebook, but you can also find the datasets in the previous folder ;) ~/project/datasets).

2. Data exploration and visualization

This part deals with the loading and preprocessing of the data; i.e., encoding the label, encoding categorical values, dropping useless features and missing values, plotting feature histograms and target distributions, etc.

3. Surrogates and splitting

This last part creates the imbalanced surrogates for each dataset and splits them into training and testing.
