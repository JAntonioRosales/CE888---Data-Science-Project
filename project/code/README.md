# Code

These are the Google Colab Notebooks I used to explore and preprocess the datasets, as well as run them on the proposed algorithm.

Feel free to run them and analyze what they do. I used Google Colab to edit these files. To access each one simply open it and click the "Open in Colab" button, at the top left corner.

Each notebook contains two main sections:

### Task 1

1. Description
   
This section presents the dataset in question. It explains its original purpose, the features it contains, and where the dataset was retrieved from (the Kaggle links are provided inside the notebook, but you can also find them in the datasets folder ;) ~/project/datasets).

2. Data exploration and visualization

This part deals with the loading and preprocessing of the data; i.e., encoding the label and categorical values, dropping useless features and missing values, plotting feature histograms and target distributions, etc.

3. Surrogates and splitting

This last part creates the imbalanced surrogates for each dataset and splits them into training and testing.

### Task 2

1. Scaling and baseline

Write here...

2. Algorithm

Write here...
